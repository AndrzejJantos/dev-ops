# Local Scraper Access Configuration
# This allows the scraper on the same machine to communicate with the API
# using http://api-scraper.localtest.me:4200
#
# Routing Architecture:
# - Port 4201: Product Read API (high-frequency polling for pending_updates)
# - Port 4202: Product Write API (product_update, batch_update, release_lock, mark_as_checked)
# - Port 4203: Normalizer API (update_normalized_attributes)
# - Port 4204: General Scraper API (all other /api/scraper/ routes)
#
# Installation on production server:
# 1. sudo cp nginx-local-scraper.conf /etc/nginx/sites-available/api-scraper-local
# 2. sudo ln -s /etc/nginx/sites-available/api-scraper-local /etc/nginx/sites-enabled/
# 3. sudo nginx -t
# 4. sudo systemctl reload nginx

# Legacy upstream (kept for reference, can be removed when migration complete)
upstream api_scraper_local_backend {
    least_conn;
    server 127.0.0.1:3020;
    server 127.0.0.1:3021;
}

# Dedicated upstreams for scraper operations
upstream product_read {
    least_conn;
    server 127.0.0.1:4201;
}

upstream product_write {
    least_conn;
    server 127.0.0.1:4202;
}

upstream normalizer {
    least_conn;
    server 127.0.0.1:4203;
}

upstream scraper_general {
    least_conn;
    server 127.0.0.1:4204;
}

# HTTP server - Local scraper access on port 4200
server {
    listen 4200;
    listen [::]:4200;

    # Accept requests for these hostnames
    server_name localhost api-scraper.localtest.me;

    # Logging
    access_log /var/log/nginx/scraper-access.log;
    error_log /var/log/nginx/scraper-error.log;

    # Client body size limit (for batch scraper uploads)
    client_max_body_size 50M;

    # Common proxy settings
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto http;
    proxy_connect_timeout 60s;
    proxy_send_timeout 180s;
    proxy_read_timeout 180s;

    # Buffer settings
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
    proxy_busy_buffers_size 8k;

    # Health check endpoint (uses general scraper)
    location /up {
        proxy_pass http://scraper_general;
        proxy_connect_timeout 5s;
        proxy_send_timeout 5s;
        proxy_read_timeout 5s;
        access_log off;
    }

    # Route READ operations to dedicated read container (high-frequency polling)
    location = /api/scraper/online_pharmacy_drugs/pending_updates {
        proxy_pass http://product_read;
    }

    # Route WRITE operations to dedicated write container
    location = /api/scraper/online_pharmacy_drugs/product_update {
        proxy_pass http://product_write;
    }

    location = /api/scraper/online_pharmacy_drugs/batch_update {
        proxy_pass http://product_write;
    }

    location = /api/scraper/online_pharmacy_drugs/release_lock {
        proxy_pass http://product_write;
    }

    location = /api/scraper/online_pharmacy_drugs/mark_as_checked {
        proxy_pass http://product_write;
    }

    # Route normalization to dedicated normalizer container
    location = /api/scraper/online_pharmacy_drugs/update_normalized_attributes {
        proxy_pass http://normalizer;
    }

    # Default: route all other requests to general scraper API
    location / {
        proxy_pass http://scraper_general;
    }
}
